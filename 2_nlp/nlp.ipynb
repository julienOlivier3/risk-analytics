{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Natural Language Processing in Risk and Finance </h1>\n",
    "<h3> <center> Developing a </h3>\n",
    "<center> <small>by <a href=\"https://juliandoerr.com\">Julian Dörr</a></small>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "_________________________\n",
    "_________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id='toc1_'></a>[About this Course](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc0_'></a>    \n",
    "- 1. [About this Course](#toc1_)    \n",
    "  - 1.1. [What you will learn](#toc1_1_)    \n",
    "- 2. [What is Natural Language Processing?](#toc2_)    \n",
    "- 3. [Application of Natural Language Processing in Risk Management](#toc3_)    \n",
    "  - 3.1. [A real-world use case: Automated Claims Processing](#toc3_1_)    \n",
    "- 4. [Developing an Automated Claims Processing Model](#toc4_)    \n",
    "  - 4.1. [Data inspection](#toc4_1_)    \n",
    "  - 4.2. [Tokenization](#toc4_2_)    \n",
    "  - 4.3. [Stopwords](#toc4_3_)    \n",
    "  - 4.4. [Vocabulary](#toc4_4_)    \n",
    "  - 4.5. [Text vectorization](#toc4_5_)    \n",
    "    - 4.5.1. [Word count vectorizer](#toc4_5_1_)    \n",
    "    - 4.5.2. [Weighted word count vectorizer](#toc4_5_2_)    \n",
    "    - 4.5.3. [Static word embeddings](#toc4_5_3_)    \n",
    "    - 4.5.4. [Contextualized embeddings](#toc4_5_4_)    \n",
    "- 5. [References](#toc5_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=4\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find all course material and setup instructions in the following [repository](https://github.com/julienOlivier3/risk-analytics/tree/main/2_nlp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. <a id='toc1_1_'></a>[What you will learn](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Fundamental Concepts**: Overview of ML and its relationship with Artificial Intelligence (AI) and Deep Learning (DL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[What is Natural Language Processing?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Processing (NLP) is a specialized branch of AI where methods from the field of Machine Learning and Deep Learning are applied to bridge the gap between human communication and machine understanding. \n",
    "\n",
    "<img src=\"img/ai_ml_dl_nlp.png\" alt=\"AI, ML, DL & NLP\" style=\"width: 45vw; min-width: 330px;\">\n",
    "<p><small>Image source: Author</small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#58e4d4\"><b>Artificial Intelligence (AI)</b></font>: **The Broad Umbrella**\n",
    "\n",
    "AI is the overarching field that encompasses all technologies and systems designed to **simulate human intelligence**. This includes tasks like reasoning, problem-solving, learning, and decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#20b49c\"><b>Machine Learning (ML)</b></font>: **The Foundation**\n",
    "\n",
    "Machine learning is a subset of AI that enables systems to **learn from data** and improve their performance over time without being explicitly programmed. ML algorithms identify patterns in data and use these patterns to **make predictions or decisions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<font color=\"#086c5c\"><b>Deep Learning (DL)</b></font>: **The Engine Behind Generative AI**\n",
    "\n",
    "Deep learning is a specialized branch of ML that uses **artificial neural networks** inspired by the human brain. These networks are particularly effective at processing large amounts of **unstructured data**, such as images, text, and audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<font color=\"#08544c\"><b>Natural Language Processing (NLP)</b></font>: **A Key Application Area**\n",
    "\n",
    "Natural language processing is a **specialized branch of AI** that focuses on **enabling machines to understand, interpret, and generate human language**. It bridges the gap between human communication and machine understanding.\n",
    "\n",
    "NLP draws on concepts from linguistics, computer science, and AI to process and analyze natural language data. It is often **powered by ML and DL techniques**, which help machines learn from vast amounts of text data and improve their language understanding capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a id='toc3_'></a>[Application of Natural Language Processing in Risk Management](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP in risk management enhances the ability to **analyze** unstructured data, such as **news articles, social media, and customer feedback, to identify potential risks, emerging trends, and fraudulent activities**. By leveraging techniques like sentiment analysis, named entity recognition, and text summarization, NLP can **automate the extraction of relevant information**, improve accuracy, and **enable faster response times**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. <a id='toc3_1_'></a>[A real-world use case: Automated Claims Processing](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will work on a real-world use case that **insurance companies** typically face. It is the process of **reviewing an insurance claim submitted by policyholders** to the insurance company. \n",
    "\n",
    "Instead of dealing with claims manually, **NLP algorithms are used to extract relevant information** from unstructured data sources: claim forms, emails, and documents. Once done, they **automatically categorise and prioritise claims** based on their severity and complexity, ensuring that urgent or complex claims receive prompt attention while routine claims are processed efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "> An **insurance claim** is a formal request made by a policyholder to an insurance company for coverage for losses or damages incurred that are covered under the insurance policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Claims processing is a multi-step process which bears great potential for automation using NLP techniques.\n",
    "\n",
    "<img src=\"img/claims_processing.png\" alt=\"Claims processing\" width=\"1000\" height=\"300\"/>\n",
    "<p><small>Image source: <a href=\"https://www.astera.com/de/type/blog/automated-claims-processing/\">Astera</a></small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a id='toc4_'></a>[Developing an Automated Claims Processing Model](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. <a id='toc4_1_'></a>[Data inspection](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claims = pd.read_csv('data/claims.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE IV WAS MAKING A LEFT TURN ON A GREEN ARROW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLAIMANT ALLEGES SHE SUFFERED INJURIES IN AN E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IV PASSENGER SUSTAINED INJURIES, OV AND IV COL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   claim_description\n",
       "0  THE IV WAS MAKING A LEFT TURN ON A GREEN ARROW...\n",
       "1  CLAIMANT ALLEGES SHE SUFFERED INJURIES IN AN E...\n",
       "2  IV PASSENGER SUSTAINED INJURIES, OV AND IV COL..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims.claim_description.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claims = df_claims[df_claims.claim_description.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191463"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data comprising 191,463 claim descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercase all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claims['claim_description'] = df_claims.claim_description.apply(lambda text: text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_11af2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_11af2_level0_col0\" class=\"col_heading level0 col0\" >claim_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_11af2_level0_row0\" class=\"row_heading level0 row0\" >124454</th>\n",
       "      <td id=\"T_11af2_row0_col0\" class=\"data row0 col0\" >iv collided into parked and unoccupied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11af2_level0_row1\" class=\"row_heading level0 row1\" >98955</th>\n",
       "      <td id=\"T_11af2_row1_col0\" class=\"data row1 col0\" >small pd. allegedly, after iv driver finished servicing the       garbage cart, a blind spot mirror was found on the residential    grounds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11af2_level0_row2\" class=\"row_heading level0 row2\" >82152</th>\n",
       "      <td id=\"T_11af2_row2_col0\" class=\"data row2 col0\" >a guest stated that someone had stolen money from her purse while dining at the restaurant. after reviewing the surveillance, it wasdetermined that an employee did steal from the claimant. no       injuries were reported.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b615bd7650>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims.sample(3).style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_claims.claim_description.apply(lambda x: len(x.split(' '))).plot.hist(bins=50, color='#1eb49c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. <a id='toc4_2_'></a>[Tokenization](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization in NLP is the process of **breaking down text into smaller units called tokens**, which can be **words, phrases, or symbols**, and it is essential for enabling machines to analyze and understand unstructured text data effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we use the `re` module to define our custom tokenization logic. Regex is a powerful tool for string manipulation and can be used to extract tokens from text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Regular expressions** (regex) are sequences of characters that define search patterns, allowing users to efficiently find, match, or manipulate strings of text based on specific criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "tokenize_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \\w: **word character** like letters (both lowercase and uppercase), digits or underscores. \\w\\w+ means that at least 2 word characters need to follow one another.\n",
    "- \\b: **word boundary** position where a word character is not followed or preceded by another word character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim = 'Broken rear window while parked. Window splinter caused damage to other vehicle.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize_pattern.findall(claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Broken',\n",
       " 'rear',\n",
       " 'window',\n",
       " 'while',\n",
       " 'parked',\n",
       " 'Window',\n",
       " 'splinter',\n",
       " 'caused',\n",
       " 'damage',\n",
       " 'to',\n",
       " 'other',\n",
       " 'vehicle']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. <a id='toc4_3_'></a>[Stopwords](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stopwords are common words in a language**, such as \"the,\" \"is,\" and \"and,\" that **carry little semantic value** and are often removed in NLP tasks to enhance the efficiency and accuracy of text analysis by focusing on more meaningful content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are pre-defined lists of stopwords for different languages. We use the English stopword list from the `nltk` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_en = [stopword.lower() for stopword in stopwords.words('english')]\n",
    "\n",
    "len(stopwords_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_en[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now tokenize the claims descriptions and remove the stopwords. Moreover, we count how often each word occurs in the corpus of claims descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In NLP, a **corpus** is a large and structured collection of authentic text data used for training, testing, and evaluating NLP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191463/191463 [00:07<00:00, 25953.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "word_counter = Counter()\n",
    "\n",
    "# Process each claim and update the word counter\n",
    "for claim_desc in tqdm(df_claims.claim_description.values):\n",
    "    # Split the claim into words using the regex pattern\n",
    "    words = tokenize_pattern.findall(claim_desc)\n",
    "\n",
    "    # Filter out empty strings and stopwords and update the counter\n",
    "    word_counter.update(word for word in words if word and word not in stopwords_en)\n",
    "\n",
    "# Convert the Counter to a dictionary\n",
    "word_frequencies = dict(word_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common words found in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iv', 76356),\n",
       " ('vehicle', 55823),\n",
       " ('damage', 47182),\n",
       " ('ov', 46567),\n",
       " ('driver', 46394),\n",
       " ('injuries', 38978),\n",
       " ('claimant', 31274),\n",
       " ('rear', 28882),\n",
       " ('front', 27656),\n",
       " ('struck', 26369)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives a clear picture of the domain of the text data: Insurance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. <a id='toc4_4_'></a>[Vocabulary](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the vocabulary which is essential for defining the scope of language the claims processing model can understand and process effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A **vocabulary** is a set of unique words in a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = sorted(set(word_frequencies.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93231"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vocabulary, comprises 93,231 distinct words which is deemed to be a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Oxford Dictionary includes about 273,000 headwords, with 171,476 currently in use, 47,156 obsolete, and around 9,500 derivatives. It features over 600,000 total word forms, while some estimates suggest the English vocabulary may reach 1 million words, including specialized and foreign terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look which words have entered our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '00000',\n",
       " '0000000115192chef',\n",
       " '0000000115196',\n",
       " '000001',\n",
       " '000001593',\n",
       " '000007',\n",
       " '000019']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to our tokenizer definition number sequences are also extracted as tokens (remember that \\w matches **word character** like letters *and* digits). Clearly, we do not want these number sequences as part of our vocabulary. Thus, we remove tokens from our vocabulary which are not part of the official English dictionary. Again, we make use of `nltk` which provides an extensive list of English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "nltk.download('words', quiet=True)\n",
    "dictionary = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {word.lower() for word in dictionary}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now reduce our vocabulary to those words which are part of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = [word for word in vocabulary if word in dictionary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16283"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with a vocabulary of 16,283 distinct words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zip',\n",
       " 'zipper',\n",
       " 'zonar',\n",
       " 'zone',\n",
       " 'zoned',\n",
       " 'zoning',\n",
       " 'zoo',\n",
       " 'zoom',\n",
       " 'zoster',\n",
       " 'zucchini']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. <a id='toc4_5_'></a>[Text vectorization](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1. <a id='toc4_5_1_'></a>[Word count vectorizer](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the simplest methods for text vectorization is the **bag-of-words (BoW) representation**, where a BoW **vector has a length equal to the entire vocabulary**, $V$, and its **values** indicate the **frequency of each word**'s occurrence, $tf$, in a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW vectorization\n",
    "\n",
    "<img src=\"img/tf.png\" alt=\"BoW\" width=\"600\">\n",
    "<p><small>Image source: Author</small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we vectorize the corpus of claims descriptions via the number of occurences of each word from the vocabulary by using `scikit-learn`'s `CountVectorizer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=vocabulary, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df_claims.claim_description.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the fitted `vectorizer`, we can now transform any string into a count vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizer.transform([claim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Vector:<br> x<sub>(1x16283)</sub> = [0 0 0 ... 1 ... 1 ... 1 ... 1 ... 1 ... 2 ... 0 0 0]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero elements:\n",
      "broken   : 1884  \t-> 1\n",
      "damage   : 3708  \t-> 1\n",
      "rear     : 11408 \t-> 1\n",
      "splinter : 13421 \t-> 1\n",
      "vehicle  : 15535 \t-> 1\n",
      "window   : 16035 \t-> 2\n"
     ]
    }
   ],
   "source": [
    "from util import print_sparse_vector\n",
    "\n",
    "print_sparse_vector(x, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting vector has $V$ = 16,283 elements with only 6 of it being non-zero. High-dimensional vectors with predominantly zero values are called **sparse vectors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Sparse vectors** are defined by their **high dimensionality**, with the **majority of** their **elements being zero**. This characteristic makes sparse vector embeddings especially valuable for traditional information retrieval tasks, like keyword matching, where identifying the presence or absence of specific terms is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words of the above claim are not part of the vocabulary because they are not in the dictionary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'parked' in dictionary, 'caused' in dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or because they are stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'while' in stopwords_en, 'to' in stopwords_en, 'other' in stopwords_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2. <a id='toc4_5_2_'></a>[Weighted word count vectorizer](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted Bag-of-Words** techniques like TF-IDF (Term Frequency-Inverse Document Frequency) **assign higher relevance to words that appear in fewer documents**, emphasizing their uniqueness by comparing a word's frequency in a specific text to its overall frequency in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-idf vectorization\n",
    "\n",
    "<img src=\"img/tf-idf.png\" alt=\"Tf-idf\" width=\"800\">\n",
    "<p><small>Image source: Author</small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use **scikit-learn**'s **TfidfVectorizer** to get a weighted term frequency representation of the claims descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=vocabulary, lowercase=True, use_idf=True, smooth_idf=False, sublinear_tf=False, norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df_claims.claim_description.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizer.transform([claim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Vector:<br> x<sub>(1x16283)</sub> = [0.0 0.0 0.0 ... 4.8 ... 2.6 ... 3.1 ... 9.8 ... 2.7 ... 11.5 ... 0.0 0.0 0.0]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero elements:\n",
      "broken   : 1884  \t-> 4.818420285039794\n",
      "damage   : 3708  \t-> 2.5850998857626366\n",
      "rear     : 11408 \t-> 3.134578877620683\n",
      "splinter : 13421 \t-> 9.761252475784687\n",
      "vehicle  : 15535 \t-> 2.6984041040430347\n",
      "window   : 16035 \t-> 11.53960467345044\n"
     ]
    }
   ],
   "source": [
    "from util import print_sparse_vector\n",
    "\n",
    "print_sparse_vector(x, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf-idf value is derived as follows:\n",
    "\n",
    "$tf\\text{-}idf = term \\, frequency \\times log\\left(\\frac{number \\, of \\, documents}{document \\, frequency}\\right) + 1 = tf \\times log\\left(\\frac{N}{df}\\right) + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word 'broken', for example, the value can be derived as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4205"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document frequency: How many documents contain the word 'broken'\n",
    "word = re.compile(r'(?u)\\bbroken\\b')\n",
    "\n",
    "df = df_claims.claim_description.apply(lambda text: bool(word.search(text))).sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191463"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of documents: How many claims are in the dataset\n",
    "N = df_claims.shape[0]\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term frequency: How many times the word 'broken' appears in the claim\n",
    "tf = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.818420285039794"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tf * np.log(N/df) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sparse, count-based methods mentioned earlier overlook the meanings of words and phrases. Words are not just letter combinations; they carry meanings and usage contexts that reflect their semantics, which go beyond their basic lexical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following vectorization techniques capture exactly those semantic properties of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.3. <a id='toc4_5_3_'></a>[Static word embeddings](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"You shall know a word by the company it keeps!\" <br> \n",
    "*Firth (1957)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that in order to represent the semantic meaning of a word, knowing its surrounding words is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec uses neural language modelling** to generate vector representations of words. This means that **Deep Learning** techniques are used to translate words into numeric vectors. These **vectors encapsulate** the **meaning of a word** by **considering** the **context provided by adjacent words**.\n",
    "\n",
    "<img src=\"img/word2vec.png\" alt=\"Word2vec\" width=\"800\">\n",
    "<p><small>Image source: Author</small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec comes in many variants. The variant below employs a shallow neural network where the learning task is to **predict surrounding words given a target word** as input. This approach is called **Continuous Bag of Words** (CBoW).\n",
    "\n",
    "<img src=\"img/word2vec_training.png\" alt=\"Word2vec\" width=\"800\">\n",
    "<p><small>Image source: Author</small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word vector representations are a by-product of the training process generated in the weights matrix in the hidden layer. The word vector representations are called word embeddings.\n",
    "\n",
    "<img src=\"img/word2vec_embedding.png\" alt=\"Word embedding\" width=\"800\">\n",
    "<p><small>Image source: Author</small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a neural language model to retrieve word embeddings for the vocabulary of our claims corpus is beyond the scope of this course. \n",
    "\n",
    "However, there are many **pre-trained word embeddings**. Moving on, we work with [**Global Vectors for Word Representation (GloVe)**](https://nlp.stanford.edu/projects/glove/) vectors that where trained on Wikipedia articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "word2vec = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-trained word embeddings come with their own vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = sorted(list(word2vec.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary comprises 400,000 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The static word embedding can then be retrieved as simple key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = word2vec.get_vector(\"window\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Vector:<br> x<sub>(1x50)</sub> = [0.671 0.5431 0.2942 ... -1.1885 0.5144 -0.7596]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util import print_vector\n",
    "\n",
    "print_vector(x, rounding_digit=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **GloVe embeddings** have only $E$ = 50 elements which is **notably smaller than** the **sparse vectors** introduced before (note their size equaled the vocabulary size $V$, with $V >> E$.). Word embeddings are referred to as **dense vectors** where **most elements contain non-zero values**, capturing rich semantic relationships and syntactic information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Dense vectors** are **lower-dimensional** vector representations of words, phrases or entire texts with **most of the elements containing non-zero values**. Dense vectors are capable to capture nuanced information such as the semantics or meaning of a piece of text and therefore shine in more complex NLP applications like semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **semantic information** captured **by word embeddings** becomes apparent when looking at the most similar words to a certain target word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('insures', 0.7770076990127563),\n",
       " ('premiums', 0.7484705448150635),\n",
       " ('uninsured', 0.7398187518119812),\n",
       " ('nonperforming', 0.7294138073921204),\n",
       " ('borrowers', 0.7286937236785889),\n",
       " ('homeowners', 0.7117431163787842),\n",
       " ('policyholders', 0.7088398933410645),\n",
       " ('compensated', 0.7084636688232422),\n",
       " ('taxpayers', 0.7040116786956787),\n",
       " ('delinquent', 0.7036601305007935)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.most_similar(\"insured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only are similar words like 'insured' and 'policyholders' close to each other in vector space, but it is also **possible to compute arithmetic expressions** such as `king - man + woman` underlying the semantic meaning captured by word embeddings.\n",
    "\n",
    "<img src=\"img/king-analogy-viz.png\" alt=\"Word arithmetics\" width=\"800\">\n",
    "<p><small>Image source: <a href=\"https://jalammar.github.io/illustrated-word2vec/\">Jay Alammar</a></small></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.8523604273796082),\n",
       " ('throne', 0.7664334177970886),\n",
       " ('prince', 0.7592144012451172),\n",
       " ('daughter', 0.7473883628845215),\n",
       " ('elizabeth', 0.7460219860076904),\n",
       " ('princess', 0.7424570322036743),\n",
       " ('kingdom', 0.7337412238121033),\n",
       " ('monarch', 0.721449077129364),\n",
       " ('eldest', 0.7184861898422241),\n",
       " ('widow', 0.7099431157112122)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.most_similar(positive=['king', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The development of **word embeddings** has significantly advanced AI's capabilities in NLP applications, yet they **still face notable challenges** in effectively representing text as meaningful vectors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Limitations to words**: While Word2Vec excels at **vectorizing individual words**, it **does not extend this capability to entire texts**, such as descriptions of claims. This restricts its utility in contexts where understanding the full meaning of phrases or sentences is crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seemingly straightforward solution for translating entire sentences, paragraphs, and documents into dense vector representations involves averaging the word embeddings to create a single text embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Broken rear window while parked. Window splinter caused damage to other vehicle.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = np.array([word2vec.get_vector(word) for word in tokenize_pattern.findall(claim.lower())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = word_embeddings.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Vector:<br> x<sub>(1x50)</sub> = [0.7038 -0.0648 0.588 ... -0.5047 0.1745 -0.563]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_vector(x, rounding_digit=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirically, however, it turns out that this approach does not yield optimal results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Static Nature of Embeddings**: Traditional static embeddings **fail to adapt to the context in which a word appears**. As a result, the **same vector** is assigned to a word **regardless of** its **varying meanings** in different sentences, leading to potential misinterpretations of context and nuance.\n",
    "\n",
    "    <img src=\"img/polysemy.png\" alt=\"Polysemy\" width=\"800\">\n",
    "    <p><small>Image source: Author</small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Unknown words**: Word2Vec is inable to handle unknown out-of-vocabulary words but can create vector presentations for the words in the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to overcome these limitations, recent advances in NLP have brought up **contextualized** (sentence) **embeddings** which we take a closer look at in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.4. <a id='toc4_5_4_'></a>[Contextualized embeddings](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most prominent and widespread way to derive contextualized embeddings are Bidirectional Encoder Representations from Transformers ([BERT](https://arxiv.org/abs/1810.04805)) by Google and its many extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of training and architectural reasons as to why BERT solves the issues faced by static embeddings. The following will give a brief overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Tokenization**: \n",
    "    - BERT uses **subword tokens** which allows to **represent out-of-vocabulary words**, for example, the common insurance term \"underwriting\" is split into the following subword tokens: `['under', '##writing']`. So even if underwriting has not been in the training corpus, BERT can still transfer it into a vector representation.\n",
    "    - BERT uses special tokens such as `[CLS]`, representing an entire sentence, and `[SEP]`, representing a token that separates two sentences from one another.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Initial Embedding Layer**: each token is converted into a **dense vector representation** through an embedding layer. This layer combines three types of embeddings:\n",
    "    - Token embeddings: Represent the meaning of each token.\n",
    "    - Position embeddings: Encode the position of each token in the sequence, allowing BERT to understand word order.\n",
    "    - Segment embeddings: Indicate whether a token belongs to the first or second sentence in tasks involving sentence pairs.\n",
    "\n",
    "    In BERT, the input embeddings are created by adding together the token embeddings, segmentation embeddings, and position embeddings.\n",
    "\n",
    "    <img src=\"img/embedding_types.png\" alt=\"Embedding types\" width=\"800\">\n",
    "    <p><small>Image source: <a href=\"https://arxiv.org/pdf/1810.04805\">Devlin et al.</a></small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Transformer Encoder Layers**: \n",
    "    - BERT uses a stack of transformer encoder layers, which apply self-attention mechanisms to compute relationships between all tokens in the input sequence. This allows BERT to capture the context of each token based on its surrounding tokens, both to the left and right (bidirectional context).\n",
    "    - the embeddings for each token are updated iteratively, incorporating more contextual information at each step.\n",
    "\n",
    "    Attention layer allows model to learn how tokens are associated to one another.\n",
    "\n",
    "    <img src=\"img/attention.png\" alt=\"Attention\" width=\"400\">\n",
    "    <p><small>Image source: <a href=\"https://mlops.community/explainable-ai-visualizing-attention-in-transformers/\">MLOps Community</a></small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Smart Pre-training Tasks**:\n",
    "    \n",
    "    - BERT employs a Masked Language Model (MLM) during pre-training. In this task, 15% of the tokens in the input are randomly masked, and the model is trained to predict these masked tokens based on their surrounding context. This approach enables BERT to learn bidirectional representations.\n",
    "\n",
    "        <img src=\"img/bert_mlm.png\" alt=\"Word embedding\" width=\"800\">\n",
    "        <p><small>Image source: Author</small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another pre-training objective is Next Sentence Prediction (NSP). BERT is trained to determine whether one sentence logically follows another. This helps the model understand relationships between sentences.\n",
    "\n",
    "    <img src=\"img/bert_nsp.png\" alt=\"Word embedding\" width=\"800\">\n",
    "    <p><small>Image source: Author</small></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a closer look at what BERT does in detail if we provide input text to it. For this purpose we download the weights of the pre-trained `bert-base-uncased` model whose training took place on a dataset consisting of 11,038 unpublished books and English Wikipedia (excluding lists, tables and headers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the model's tokenizer to first tokenize the input text and then use the model to create contextualized embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(claim, return_tensors='pt')\n",
    "output = bert(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
      " 'input_ids': tensor([[  101,  3714,  4373,  3332,  2096,  9083,  1012,  3332, 27546,  3303,\n",
      "          4053,  2000,  2060,  4316,  1012,   102]]),\n",
      " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'broken',\n",
       " 'rear',\n",
       " 'window',\n",
       " 'while',\n",
       " 'parked',\n",
       " '.',\n",
       " 'window',\n",
       " 'splinter',\n",
       " 'caused',\n",
       " 'damage',\n",
       " 'to',\n",
       " 'other',\n",
       " 'vehicle',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'].tolist()[0])\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Contextualized BERT embeddings:<table><br><tr><td>[CLS]    -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [-1.067245 -0.473966 -0.625546 ... -0.067991 -0.097224 0.155587]</td></tr><tr><td>broken   -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [-0.689901 0.039249 -0.585899 ... -0.476481 0.070014 -0.352241]</td></tr><tr><td>rear     -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [-0.213742 -0.371267 0.071303 ... -1.099853 -0.460982 -0.930986]</td></tr><tr><td>window   -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [0.200246 -0.116219 -0.029177 ... -0.528522 -0.915092 -0.420982]</td></tr><tr><td>while    -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [-1.045992 -0.631917 -0.189136 ... -0.716261 -0.706866 -0.547814]</td></tr><tr><td>parked   -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [0.777781 -0.811725 0.338238 ... -0.765841 -0.795694 -0.029895]</td></tr><tr><td>.        -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [-0.826803 -0.489583 -0.469647 ... 0.414048 -0.116963 -0.340693]</td></tr><tr><td>window   -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [0.460724 -0.24496 0.18525 ... -0.410692 -0.437089 -0.046866]</td></tr><tr><td>splinter -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [0.261998 -0.126327 -0.162649 ... -0.468058 -0.699804 -0.433032]</td></tr><tr><td>caused   -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [-0.425447 -0.494747 0.009462 ... -0.283312 -0.724969 -0.068895]</td></tr><tr><td>damage   -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [-0.395371 -0.230687 -0.325486 ... -0.66382 -0.761551 0.108998]</td></tr><tr><td>to       -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [-0.378422 0.027019 0.160512 ... -0.051474 -0.04372 0.1986]</td></tr><tr><td>other    -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [-0.615714 -0.731684 0.179486 ... -0.904363 -0.043309 -0.779503]</td></tr><tr><td>vehicle  -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [0.333605 -0.290167 0.073741 ... -0.704118 -0.161031 -0.062333]</td></tr><tr><td>.        -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [-0.583203 -0.951438 -0.36437 ... 0.635906 -0.0654 -0.226699]</td></tr><tr><td>[SEP]    -> </td>\n",
       "        <td style='text-align:left'>x<sub>(1x768)</sub> = [0.748099 0.009724 -0.508421 ... 0.385983 -0.498488 -0.040788]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util import print_bert_vector\n",
    "\n",
    "print_bert_vector(output.last_hidden_state, tokens)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may observe a few key aspects:\n",
    "1. The special tokens `[CLS]` and `[SEP]` each have their own unique embeddings.\n",
    "2. Punctuation marks are represented by their own distinct embeddings.\n",
    "3. The token embeddings for the word \"window\" are not identical; they vary due to the different contexts in which they appear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one last step to take for our claims descriptions to be transferred into fixed-size highly contextualized embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While BERT captures contextual information at the token level, its default embeddings are not fine-tuned to capture semantic relationships between entire sentences. To generate sentence embeddings, you typically need to pool or average the token embeddings (e.g., mean pooling or using the `[CLS]` token). However, this approach often results in embeddings that are not optimal for sentence similarity or clustering tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This issue is solved by Sentence Transformers ([SBERT](https://sbert.net/#)) which essentially fine-tunes BERT using specific training objectives that encourage sentence embeddings to align with semantic similarity. It does so by using a dataset that contains sentence pairs labeled for entailment, contradiction, and semantic independence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on we will work with SBERT embeddings using the `sentence-transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sbert.encode(claim, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: round() received an invalid combination of arguments - got (decimals=int, out=NoneType, ), but expected one of:\n * ()\n * (*, int decimals)\n      didn't match because some of the keywords were incorrect: out\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprint_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrounding_digit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\2_nlp\\util.py:45\u001b[0m, in \u001b[0;36mprint_vector\u001b[1;34m(vector, rounding_digit, string, return_output)\u001b[0m\n\u001b[0;32m     42\u001b[0m     vector \u001b[38;5;241m=\u001b[39m vector\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Round the elements to the specified number of decimal places\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m rounded_vector \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrounding_digit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Get the indices of non-zero elements\u001b[39;00m\n\u001b[0;32m     48\u001b[0m non_zero_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnonzero(rounded_vector)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3360\u001b[0m, in \u001b[0;36mround\u001b[1;34m(a, decimals, out)\u001b[0m\n\u001b[0;32m   3269\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_round_dispatcher)\n\u001b[0;32m   3270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mround\u001b[39m(a, decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3271\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3272\u001b[0m \u001b[38;5;124;03m    Evenly round to the given number of decimals.\u001b[39;00m\n\u001b[0;32m   3273\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3358\u001b[0m \n\u001b[0;32m   3359\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mround\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecimals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:68\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:45\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m, method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\torch\\_tensor.py:1194\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "print_vector(x, rounding_digit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the SBERT embeddings we can now show that text that is semantically similar is close in vector space. While semantic distinct text is distant in vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a id='toc5_'></a>[References](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [What Is Text Vectorization? Everything You Need to Know](https://www.deepset.ai/blog/what-is-text-vectorization-in-nlp)\n",
    "- [The Illustrated Word2vec](https://jalammar.github.io/illustrated-word2vec/)\n",
    "- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
