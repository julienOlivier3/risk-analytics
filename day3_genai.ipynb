{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative AI and Risk Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Generative AI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Generative AI (GenAI) is a special type of Artificial Intelligence that can learn from and mimic large amounts of data to create content such as text, images, music, videos, code, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Generative AI in Risk Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Information analysis\n",
    "- Information provision\n",
    "- Information automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pwc.com/us/en/industries/financial-services/library/gen-ai-and-risk-management.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Proof-of-Concept (PoC): Risk Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the course we will develop a conversational AI that provides seamless information about risks and challenges faced by publicly listed companies based on their annual reports. More precisely we will develop an application where a Large Language Model (LLM) orchestrates user queries to the annual reports that are relevant for the query. The user's query will then be enriched with information from the relevant reports which allows the LLM to come up with answers that closely reflect the information from the reports. In other words, the generated answers from the LLM are tuned by a retrieval mechanism that adds domain knowledge to the LLM's response which it otherwise would not have from its mere pretraining. This mechanism is called Retrieval Augmented Generation (RAG) and is a quite popular approach when developing conversational GenAI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LLMs, are very large deep learning models that are pre-trained on vast amounts of data. They are highly flexible as a single model can perform completely different generative tasks such as answering questions, summarizing documents, translating languages and completing sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While risk-related information from company reports is publicly available, it is quite tedious and resource-intensive to collect and structure it and to make it seamless available to decision makers that act upon such information. For example,\n",
    "- Financial Analysts and Investment Professionals such as portfolio managers, equity analysts, and hedge fund managers, need to assess the risks and challenges of companies to make informed investment decisions. A risk agent could help them quickly analyze risk disclosures in annual reports, saving time and improving accuracy.\n",
    "- Corporate Risk Managers need to benchmark their own risk disclosures against competitors or industry standards. A risk agent could help them identify trends in risk reporting and ensure compliance with regulatory requirements.\n",
    "- ESG analysts focus on evaluating companies' sustainability and governance practices. Risk disclosures in annual reports often include information about environmental and social risks, which are critical for ESG assessments. A risk agent could help them extracting and analyzing ESG-related risks from annual reports to evaluate a company's sustainability profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing LLM-based applications requires you to choose one of the many proprietary or open-source LLM models. We use the proprietary LLM `command-r-plus` from [Cohere](https://cohere.com/command). Cohere offers trial API keys that can be used to send calls to their LLMs and return responses free of charge. Cohere's trial keys are rate-limited, and cannot be used for commercial purposes.\n",
    "\n",
    "In order to get a trial API key, [create an account](https://dashboard.cohere.com/welcome/register) on Cohere and generate a trial API key.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/cohere.png\" alt=\"Cohere trial key\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the root directory of this project simply create a new file named `.env` where you paste in your trial API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/env.png\" alt=\".env file\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step, we load the API keys into your project's environment, so the keys are available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API keys\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, we will primarily work with [LlamaIndex](https://docs.llamaindex.ai/en/stable/) which is one of the leading frameworks for building LLM-powered agents.\n",
    "\n",
    "> Agents are LLM-powered knowledge assistants that use tools to perform tasks like research, data extraction, and more. Agents range from simple question-answering to being able to sense, decide and take actions in order to complete tasks.\n",
    "\n",
    "LlamaIndex provides the following tools that formalize the development of search agents:\n",
    "- **Data connectors** (Readers) ingest existing data from their native source and format. These could be APIs, PDFs, SQL databases, and others.\n",
    "- **Data indexes** structure your data in intermediate representations that are easy and performant for LLMs to consume.\n",
    "- **Engines** provide natural language access to your data. For example:\n",
    "    - Query engines are powerful interfaces for question-answering (e.g. a RAG flow).\n",
    "    - Chat engines are conversational interfaces for multi-message, \"back and forth\" interactions with your data.\n",
    "- **Agents** are LLM-powered knowledge workers augmented by tools, from simple helper functions to API integrations and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our use case, we develop an agent capable of extracting risk-related information from annual company reports. The agent orchestrates which report to retrieve information from based on the user's query. The illustration below provides an idea of what such a system may look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/multi_doc_agent.webp\" alt=\"Multi-document agent\" width=\"900\">\n",
    "<p>Image source: <a href=\"https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6\">Ivan Ilin</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a Mulit-Document Risk Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstrative purposes, the original annual reports for a sample of DAX 40 companies can be found in `data/raw/reports/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adidas_2023.pdf',\n",
       " 'allianz_2023.pdf',\n",
       " 'basf_2023.pdf',\n",
       " 'bayer_2023.pdf',\n",
       " 'beiersdorf_2023.pdf',\n",
       " 'bmw_2023.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports = os.listdir('data/raw/reports/')\n",
    "reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the annual reports we use `SimpleDirectoryReader` which provides a simple and straightforward way to load data from local files and parse the text found in them automatically selecting the best file reader based on the file extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 6/6 [03:47<00:00, 37.93s/file]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1735"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('data/raw/reports/').load_data(show_progress=True)\n",
    "print(f\"In total {len(documents)} Document objects have been loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see `SimpleDirectoryReader` returns a list of `Document` objects where each element represents a single page from the annual reports loaded before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='9e9bcf34-1f19-40c4-849c-c1e477945867', embedding=None, metadata={'page_label': '1', 'file_name': 'adidas_2023.pdf', 'file_path': 'w:\\\\teaching\\\\risk_analytics\\\\data\\\\raw\\\\reports\\\\adidas_2023.pdf', 'file_type': 'application/pdf', 'file_size': 20968677, 'creation_date': '2025-02-02', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='2023\\nANNUAL REPORT', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='9978232f-cae8-40fb-a671-d730513fab90', embedding=None, metadata={'page_label': '2', 'file_name': 'adidas_2023.pdf', 'file_path': 'w:\\\\teaching\\\\risk_analytics\\\\data\\\\raw\\\\reports\\\\adidas_2023.pdf', 'file_type': 'application/pdf', 'file_size': 20968677, 'creation_date': '2025-02-02', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='YOU\\nGOT\\nTHIS\\nANNUAL REPORT 2023', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='be93d4e5-9418-467f-b6cf-262be06072c4', embedding=None, metadata={'page_label': '3', 'file_name': 'adidas_2023.pdf', 'file_path': 'w:\\\\teaching\\\\risk_analytics\\\\data\\\\raw\\\\reports\\\\adidas_2023.pdf', 'file_type': 'application/pdf', 'file_size': 20968677, 'creation_date': '2025-02-02', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='OUR PURPOSE\\nOUR MISSION \\nTO BE THE BEST SPORTS BRAND IN THE WORLD\\nTOTHE\\nTHROUGH\\nSP ORT,\\nPOWER\\nCHANGE LIVES\\nWE HAVE\\nANNUAL REPORT 2023', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Document` object comes with a unique ID, some metadate, and the data found in the document by data type:\n",
    "- text_resource\n",
    "- image_resource\n",
    "- audio_resource\n",
    "- video_resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': '49b503ab-4c12-498c-b921-057f41885a8f',\n",
       " 'embedding': None,\n",
       " 'metadata': {'page_label': '101',\n",
       "  'file_name': 'adidas_2023.pdf',\n",
       "  'file_path': 'w:\\\\teaching\\\\risk_analytics\\\\data\\\\raw\\\\reports\\\\adidas_2023.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 20968677,\n",
       "  'creation_date': '2025-02-02',\n",
       "  'last_modified_date': '2025-02-02'},\n",
       " 'excluded_embed_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'excluded_llm_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'relationships': {},\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_separator': '\\n',\n",
       " 'text_resource': MediaResource(embeddings=None, data=None, text='1 2 3 4 5 \\nT O  O U R SHA REHO L D ERS  GRO U P  MAN A GEMEN T  REP O RT – \\nO U R CO MPA N Y \\nGRO U P  MAN A GEMEN T  REP O RT – \\nF I N A N CI AL  REVI EW \\nCO N SO L I DA T ED  FI N AN CI A L \\nST A T EMEN T S \\nA D D I T I ON A L I N FO RMA T I ON \\n \\n101 \\n    \\n    \\n A N N U A L  R E P O R T 2 0 2 3 \\n─ Fair compensation: We are currently conducting a multi-year wage benchmarking exercise with our \\nstrategic suppliers.21 Data is being gathered from three different time periods: our 2020 benchmark \\nyear, our 2023 mid-term year, and our 2025 final year. The data reported for the 2020 benchmark year \\ndata was collected from 2021-2023, the 2023 mid-term year data will be collected in 2024, and the \\n2025 data will be collected in 2026. In 2023, we completed the 2020 benchmarking by collecting wage \\ndata in China, Thailand, and Pakistan.22 In line with the benchmarking completed in Cambodia, \\nIndonesia, and Vietnam in the previous year, we compared factory wage data to external benchmarks, \\nsuch as the applicable legal minimum wage, the FLA Country Average, which is an industry average \\nbased on suppliers working with FLA member companies, and the Global Living Wage Coalition \\n(‘GLWC’) benchmark, where available.  \\nResults of our entire benchmarking period 2020 show that the wages paid by the suppliers in scope for this \\nexercise (representing around 80% of all strategic suppliers) exceed all of the aforementioned \\nbenchmarks. In line with the FLA Fair Compensation formula, all wages reported below include regular \\nwages, paid leave, applicable and eligible incentives, benefits in kind and cash benefits, and exclude all \\nlegally required taxes and social insurance contributions. \\n─ Cambodia (ten factories): In our major sourcing country for apparel, wages paid by adidas \\nsuppliers surpassed the legal gross minimum wage by 56% and the applicable net FLA Country \\nAverage by 33%. In the case of Cambodia, 90% of the factories assessed are unionized, while 10% \\nhave a collective bargaining agreement (CBA) in place. \\n─ China (14 factories): The factories assessed in China are located within ten different gross \\nminimum wage groups. Across all minimum wage groups, factories’ net wages surpassed their \\napplicable minimum wage requirement by between 13% and 159%. Currently, two of our data \\ncollection in-scope factories with an available and applicable GLWC benchmark surpassed their \\nGLWC benchmark by 2% and 34%, respectively. In China, 79% of these factories have a state-\\nbacked trade union, and 43% a CBA in place.  \\n─ Indonesia (13 factories): The factories assessed in Indonesia are located within ten different legal \\ngross minimum wage groups, which vary widely in terms of minimum wage requirements. Across \\nall minimum wage groups, wages paid surpassed the legal minimum wage by between 9% and \\n66%; 92% of factories are unionized and have a CBA in place. \\n─ Pakistan (two factories): The data shows that wages paid by adidas suppliers surpassed the legal \\ngross minimum wage by 42% and the applicable net FLA Country Average by 16%. Currently, \\nnone of the factories in scope in Pakistan are unionized. \\n─ Thailand (four factories): The factories assessed in Thailand are located within three different \\ngross minimum wage groups. Across all minimum wage groups, wages paid surpassed the legal \\ngross minimum wage by between 36% and 44%. Currently, none of the factories are unionized. \\n  \\n \\n21 Strategic suppliers as of January 2020.  \\n22 Data as reported in the 2022 Annual Report included 2020 benchmarking results from wage data collected in 2021 in Cambodia, Indonesia, and Vietnam \\n(approximately 65% of our selected factories are located in these three countries). The reporting in this 2023 Annual Report reflects the full 2020 benchmarking \\nresults from all wage data collected between 2021-2023 from all of our factories in scope for this exercise located in our three initial countries (Cambodia, \\nIndonesia, Vietnam), in addition to in-scope factories in China, Pakistan, and Thailand. A small number of factories in four different countries were initially \\nconsidered for data collection and reporting. Due to the minor production volume they represent in their country and to protect their confidentiality, they have \\nbeen subsequently removed from the scope. ', path=None, url=None, mimetype=None),\n",
       " 'image_resource': None,\n",
       " 'audio_resource': None,\n",
       " 'video_resource': None,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(documents[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the custom function `display_document_with_image_side_by_side()` to display and compare the text parsed by `SimpleDirectoryReader` with the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"display: flex; align-items: flex-start;\">\n",
       "        <div style=\"flex: 1; padding: 10px;\">\n",
       "            <pre>1 2 3 4 5 \n",
       "T O  O U R SHA REHO L D ERS  GRO U P  MAN A GEMEN T  REP O RT – \n",
       "O U R CO MPA N Y \n",
       "GRO U P  MAN A GEMEN T  REP O RT – \n",
       "F I N A N CI AL  REVI EW  \n",
       "CO N SO L I DA T ED  FI N AN CI A L \n",
       "ST A T EMEN T S \n",
       "A D D I T I ON A L I N FO RMA T I ON \n",
       " \n",
       "166 \n",
       "    \n",
       "    \n",
       " A N N U A L  R E P O R T  2 0 2 3 \n",
       "Risk and Opportunity Report \n",
       "In order to remain competitive and ensure sustainable success, adidas consciously takes risks and \n",
       "continuously explores and develops opportunities. Our risk and opportunity management principles and \n",
       "system provide the framework for our company to conduct business in a well-controlled environment. \n",
       "Risk and opportunity management principles \n",
       "The key objective of the risk and opportunity management is to support business success and protect the \n",
       "company as a going concern through an opportunity-focused but risk-aware decision-making framework. \n",
       "Our Enterprise Risk Management Policy outlines the principles, processes, tools, risk areas, key \n",
       "responsibilities, reporting requirements, and communication timelines within our company. Risk and \n",
       "opportunity management is a company-wide activity that utilizes key insights from the members of the \n",
       "Executive Board as well as from global and local business units and functions. We define risk as the \n",
       "potential occurrence of an external or internal event (or series of events) that may negatively impact our \n",
       "ability to achieve the company’s business objectives or financial goals. Opportunity is defined as the \n",
       "potential occurrence of an external or internal event (or series of events) that can positively impact the \n",
       "company’s ability to achieve its business objectives or financial goals. \n",
       "Risk and opportunity management system \n",
       "The Executive Board has overall responsibility for establishing a risk and opportunity management system \n",
       "that ensures comprehensive and consistent management of all relevant risks and opportunities. The \n",
       "Enterprise Risk Management department governs, operates, and develops the company’s risk and \n",
       "opportunity management system and is the owner of the centrally managed risk and opportunity \n",
       "management process on behalf of the Executive Board. The Supervisory Board is responsible for \n",
       "monitoring the effectiveness of the risk management system. These duties are undertaken by the \n",
       "Supervisory Board’s Audit Committee. Working independently of all other functions of the organization, the \n",
       "Internal Audit department provides objective assurance to the Executive Board and the Audit Committee \n",
       "regarding the adequacy and effectiveness of the company’s risk and opportunity management system on a \n",
       "regular basis. In addition, the Internal Audit department includes an assessment of the effectiveness of \n",
       "risk management processes and compliance with the company’s Enterprise Risk Management Policy as \n",
       "part of its regular auditing activities with selected adidas subsidiaries or functions each year. \n",
       "Our risk and opportunity management system is based on frameworks for enterprise risk management \n",
       "and internal controls developed and published by the Committee of Sponsoring Organizations of the \n",
       "Treadway Commission (COSO). Additionally, we have adapted our risk and opportunity management \n",
       "system to more appropriately reflect the structure as well as the culture of the company. This system \n",
       "focuses on the identification, evaluation, handling, systematic reporting, and monitoring of risks and \n",
       "opportunities. Furthermore, we use a quantitative concept for risk capacity and risk appetite. Risk capacity \n",
       "is a liquidity-based measure and represents the maximum level of risk adidas AG can take before being \n",
       "threatened with insolvency. Risk appetite refers to the maximum level of risk the company is willing to \n",
       "take and is linked to the company's liquidity targets.</pre>\n",
       "        </div>\n",
       "        <div style=\"flex: 1; padding: 10px;\">\n",
       "            <img src=\"img/annual_report.png\" style=\"max-width: 100%; height: auto;\">\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util import display_document_with_image_side_by_side\n",
    "\n",
    "display_document_with_image_side_by_side(\n",
    "    document=documents[165],\n",
    "    image_path='img/annual_report.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the text_resource in the Risk Agent, we do not need the header information which repeats on each page. This is just convoluting the content and should be removed from the `Document` objects. Similar redundant text can be found in the annual reports of the other companies. Moreover, we do not want to use the entire annual reports but only the pages which contain information the companies' 'Risk and Opportunity'. Ultimately, we want to merge all relevant pages of one annual report into a single `Document` object. Otherwise, paragraphs that split across two pages will be handled separately in downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process_dict = {\n",
    "    \"adidas\": {\n",
    "        \"pages\": range(166, 187, 1),\n",
    "        \"string_to_remove\": \"1 2 3 4 5 \\nT O  O U R SHA REHO L D ERS  GRO U P  MAN A GEMEN T  REP O RT – \\nO U R CO MPA N Y \\nGRO U P  MAN A GEMEN T  REP O RT – \\nF I N A N CI AL  REVI EW  \\nCO N SO L I DA T ED  FI N AN CI A L \\nST A T EMEN T S \\nA D D I T I ON A L I N FO RMA T I ON \\n \\n\\\\d{1,3} \\n    \\n    \\n A N N U A L  R E P O R T  2 0 2 3\",\n",
    "    },\n",
    "    \"allianz\": {\n",
    "        \"pages\": range(21, 35, 1),\n",
    "        \"string_to_remove\": \"B _ Management Report of Allianz SE \\n\\\\d{1,3} Annual Report 2023 – Allianz SE \\n\"\n",
    "    },\n",
    "    \"basf\": {\n",
    "        \"pages\": range(172, 184, 1),\n",
    "        \"string_to_remove\": \"Combined Management’s Report – Opportunities and Risks\\n\"\n",
    "    },\n",
    "    \"bayer\": {\n",
    "        \"pages\": range(100, 116, 1),\n",
    "        \"string_to_remove\": \" \\n \\nBayer Annual Report 2023 A Combined Management Report\\n3.2 Opportunity and Risk Report\\n \\\\d{1,3}\\n\"\n",
    "    },\n",
    "    \"beiersdorf\": {\n",
    "        \"pages\": range(155, 166, 1),\n",
    "        \"string_to_remove\": \" \\n \\nBeiersdorf Annual Report 2023 A Combined Management Report\\n3.2 Opportunity and Risk Report\\n \\\\d{1,3}\\n\"\n",
    "    },\n",
    "    \"bmw\": {\n",
    "        \"pages\": range(126, 142, 1),\n",
    "        \"string_to_remove\": \"\\\\d{1,3} BMW Group Report 2023\\\\s+To Our Stakeholders\\\\s+Combined Management Report\\\\s+Group Financial Statements\\\\s+Responsibility Statement and Auditor’s Report\\\\s+Remuneration Report\\\\s+Other Information\\\\s+\\n\\\\s+Risks and Opportunities\\\\s+\\n\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "import re\n",
    "\n",
    "def pre_process_document(report_file_path:str, pre_process_dict:dict=None):\n",
    "\n",
    "    documents = SimpleDirectoryReader(input_files=[report_file_path]).load_data(show_progress=True)\n",
    "    \n",
    "    overall_text = \"\"\n",
    "    if pre_process_dict is not None:\n",
    "        string_to_remove = pre_process_dict.get('string_to_remove')\n",
    "        pages = pre_process_dict.get('pages')\n",
    "    else:\n",
    "        pages = range(0, len(documents), 1)\n",
    "\n",
    "    for page in pages:\n",
    "        document = documents[page]\n",
    "        text = document.text\n",
    "        if string_to_remove is not None:\n",
    "            text = re.sub(string_to_remove, \"\", text)\n",
    "        overall_text = \"\\n\".join([overall_text, text])\n",
    "\n",
    "    documents = [Document(text=overall_text)]\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 1/1 [00:27<00:00, 27.59s/file]\n"
     ]
    }
   ],
   "source": [
    "temp = pre_process_document('data/raw/reports/adidas_2023.pdf', pre_process_dict.get('adidas'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    load_index_from_storage,\n",
    "    SummaryIndex,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext\n",
    ")\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.llms.cohere import Cohere\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.huggingface_api import HuggingFaceInferenceAPIEmbedding\n",
    "from tqdm import tqdm\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "from pathlib import Path\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [\n",
    "    'adidas',\n",
    "    'allianz',\n",
    "    'basf',\n",
    "    'bayer',\n",
    "    'beiersdorf',\n",
    "    'bmw'\n",
    "    ]\n",
    "\n",
    "year = '2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_doc_tools(\n",
    "    company_fp: str,\n",
    "    company: int,\n",
    "    post_process: dict = None,\n",
    "    llm_model = Cohere(model=\"command-r-plus\", api_key=cohere_api_key),\n",
    "    embed_model = HuggingFaceInferenceAPIEmbedding(model_name=\"Snowflake/snowflake-arctic-embed-l-v2.0\", token=huggingface_api_key),\n",
    ") -> AgentRunner:\n",
    "    \n",
    "    # LLM model\n",
    "    Settings.llm = llm_model\n",
    "    # embedding model\n",
    "    Settings.embed_model = embed_model\n",
    "\n",
    "    if not os.path.exists(f\"./data/reports/{company}\"):\n",
    "        # load pdf documents\n",
    "        documents = SimpleDirectoryReader(input_files=[company_fp]).load_data()\n",
    "\n",
    "        if post_process is not None:\n",
    "            overall_text = \"\"\n",
    "            string_to_remove = post_process.get('string_to_remove')\n",
    "            for page in post_process.get('pages'):\n",
    "                document = documents[page]\n",
    "                text = document.text\n",
    "                if string_to_remove is not None:\n",
    "                    text = re.sub(string_to_remove, \"\", text)\n",
    "                overall_text = \"\\n\".join([overall_text, text])\n",
    "            documents = [Document(text=overall_text)]\n",
    "        \n",
    "        splitter = SentenceSplitter()\n",
    "        nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "        # summary index\n",
    "        summary_index = SummaryIndex(nodes)\n",
    "        summary_index.storage_context.persist(\n",
    "            persist_dir=f\"./data/reports/{company}/summary_index\"\n",
    "        )\n",
    "        # vector store index\n",
    "        vector_index = VectorStoreIndex(\n",
    "            nodes,\n",
    "            embed_model=Settings.embed_model)\n",
    "        vector_index.storage_context.persist(\n",
    "            persist_dir=f\"./data/reports/{company}/vector_index\"\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        summary_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(\n",
    "                persist_dir=f\"./data/reports/{company}/summary_index\"\n",
    "            )\n",
    "        )\n",
    "        vector_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(\n",
    "                persist_dir=f\"./data/reports/{company}/vector_index\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    # Summary query engine based on a\n",
    "    # simple retriever returns all nodes\n",
    "    summary_query_engine = summary_index.as_query_engine()\n",
    "\n",
    "    # Vector query engine based on a\n",
    "    # vector index retriever that only returns the top k results\n",
    "    vector_query_engine = vector_index.as_query_engine(similarity_top_k=2)\n",
    "\n",
    "    # define tools\n",
    "    query_engine_tools = [\n",
    "        QueryEngineTool.from_defaults(\n",
    "            name=f\"{company}_summary_tool\",\n",
    "            query_engine=summary_query_engine,\n",
    "            description=(\n",
    "                f\"Useful for summarization questions related to the risks outlined in the annual report of {company}.\"\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "        QueryEngineTool.from_defaults(\n",
    "            name=f\"{company}_vector_tool\",\n",
    "            query_engine=vector_query_engine,\n",
    "            description=(\n",
    "                f\"Useful for retrieving specific context concerning {company}'s risks and challenges as highlighted in its annual report.\"\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "        query_engine_tools, \n",
    "        llm=Settings.llm, \n",
    "        verbose=True,\n",
    "        system_prompt=f\"\"\"\n",
    "        You are an agent designed to answer queries about the company {company} which can be answered based on paragraphs \n",
    "        from their annual reports where they outline their risks and challenges.\n",
    "        \n",
    "\n",
    "\n",
    "        Please always use the tools provided to answer a question. Do NOT rely on prior knowledge.\n",
    "        \"\"\"\n",
    "    )\n",
    "    agent = AgentRunner(agent_worker)\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  5.95it/s]\n"
     ]
    }
   ],
   "source": [
    "agents = {}\n",
    "for company in tqdm(companies):\n",
    "    agent = await create_doc_tools(\n",
    "        company_fp = Path(f\"./data/raw/reports/{company}_{year}.pdf\"),\n",
    "        company = company,\n",
    "        post_process = post_process[company])\n",
    "    agents[company] = agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# define tool for each document agent\n",
    "all_tools = []\n",
    "for company in tqdm(companies):\n",
    "    report_summary = (\n",
    "        f\"This content contains information about {company}'s annual report. Use\"\n",
    "        f\" this tool if you want to answer any questions about {company}.\\n\"\n",
    "    )\n",
    "    doc_tool = QueryEngineTool(\n",
    "        query_engine=agents[company],\n",
    "        metadata=ToolMetadata(\n",
    "            name=f\"tool_{company}\",\n",
    "            description=report_summary,\n",
    "        ),\n",
    "    )\n",
    "    all_tools.append(doc_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot run the event loop while another loop is running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m obj_index \u001b[38;5;241m=\u001b[39m \u001b[43mObjectIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_tools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVectorStoreIndex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\objects\\base.py:172\u001b[0m, in \u001b[0;36mObjectIndex.from_objects\u001b[1;34m(cls, objects, object_mapping, from_node_fn, to_node_fn, index_cls, **index_kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     object_mapping \u001b[38;5;241m=\u001b[39m get_object_mapping(\n\u001b[0;32m    166\u001b[0m         objects,\n\u001b[0;32m    167\u001b[0m         from_node_fn\u001b[38;5;241m=\u001b[39mfrom_node_fn,\n\u001b[0;32m    168\u001b[0m         to_node_fn\u001b[38;5;241m=\u001b[39mto_node_fn,\n\u001b[0;32m    169\u001b[0m     )\n\u001b[0;32m    171\u001b[0m nodes \u001b[38;5;241m=\u001b[39m object_mapping\u001b[38;5;241m.\u001b[39mto_nodes(objects)\n\u001b[1;32m--> 172\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mindex_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mindex_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(index, object_mapping)\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:76\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     70\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embed_model\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m Settings\u001b[38;5;241m.\u001b[39membed_model\n\u001b[0;32m     73\u001b[0m )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:77\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m---> 77\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:310\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content_nodes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(nodes):\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome nodes are missing content, skipping them...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:279\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:232\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nodes_batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size):\n\u001b[1;32m--> 232\u001b[0m     nodes_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_with_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m     new_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39madd(nodes_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minsert_kwargs)\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mstores_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override:\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;66;03m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:139\u001b[0m, in \u001b[0;36mVectorStoreIndex._get_node_with_embedding\u001b[1;34m(self, nodes, show_progress)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_node_with_embedding\u001b[39m(\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    129\u001b[0m     nodes: Sequence[BaseNode],\n\u001b[0;32m    130\u001b[0m     show_progress: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    131\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseNode]:\n\u001b[0;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    Get tuples of id, node, and embedding.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m \n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m     id_to_embed_map \u001b[38;5;241m=\u001b[39m \u001b[43membed_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\utils.py:160\u001b[0m, in \u001b[0;36membed_nodes\u001b[1;34m(nodes, embed_model, show_progress)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m         id_to_embed_map[node\u001b[38;5;241m.\u001b[39mnode_id] \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39membedding\n\u001b[1;32m--> 160\u001b[0m new_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membed_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_embedding_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts_to_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_id, text_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[0;32m    165\u001b[0m     id_to_embed_map[new_id] \u001b[38;5;241m=\u001b[39m text_embedding\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py:335\u001b[0m, in \u001b[0;36mBaseEmbedding.get_text_embedding_batch\u001b[1;34m(self, texts, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    327\u001b[0m     EmbeddingStartEvent(\n\u001b[0;32m    328\u001b[0m         model_dict\u001b[38;5;241m=\u001b[39mmodel_dict,\n\u001b[0;32m    329\u001b[0m     )\n\u001b[0;32m    330\u001b[0m )\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    332\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mEMBEDDING,\n\u001b[0;32m    333\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mSERIALIZED: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dict()},\n\u001b[0;32m    334\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m--> 335\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_text_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     result_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[0;32m    337\u001b[0m     event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[0;32m    338\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    339\u001b[0m             EventPayload\u001b[38;5;241m.\u001b[39mCHUNKS: cur_batch,\n\u001b[0;32m    340\u001b[0m             EventPayload\u001b[38;5;241m.\u001b[39mEMBEDDINGS: embeddings,\n\u001b[0;32m    341\u001b[0m         },\n\u001b[0;32m    342\u001b[0m     )\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\embeddings\\huggingface\\base.py:517\u001b[0m, in \u001b[0;36mHuggingFaceInferenceAPIEmbedding._get_text_embeddings\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    514\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    515\u001b[0m         loop\u001b[38;5;241m.\u001b[39mcreate_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aget_text_embedding(text)) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts\n\u001b[0;32m    516\u001b[0m     ]\n\u001b[1;32m--> 517\u001b[0m     \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     loop\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\asyncio\\base_events.py:640\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m--> 640\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    642\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[0;32m    643\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\asyncio\\base_events.py:601\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot run the event loop while another loop is running"
     ]
    }
   ],
   "source": [
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_index.as_retriever(\n",
    "        similarity_top_k=3,\n",
    "        node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.8)]\n",
    "        ),\n",
    "    system_prompt=\"\"\"\n",
    "        You are an agent designed to answer queries about a set of given companies.\n",
    "        Please always try to use the tools provided to answer a question. \n",
    "        If none of the tools can be used to answer the question, respond to the user\n",
    "        that you do not have any information available about the company he is asking.\\n\n",
    "        \"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "top_agent = AgentRunner(top_agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What does the Norvatis mention about litigation risks in its annual report?\n",
      "=== LLM Response ===\n",
      "I'm sorry, I can only answer questions about BMW.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"I'm sorry, I can only answer questions about BMW.\", sources=[], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat(\"What does the Norvatis mention about litigation risks in its annual report?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Do BMW or Astra Zeneca face residual value risks and how they mitigate these risks?\n",
      "=== LLM Response ===\n",
      "I can provide some general information about residual value risk, but I don't have specific risk mitigation strategies for BMW or AstraZeneca. Here's what I can tell you:\n",
      "\n",
      "Residual value risk is the potential financial risk associated with the future value of an asset at the end of its lease or useful life. This risk is relevant for companies that deal with assets that depreciate over time, such as vehicles or equipment.\n",
      "\n",
      "For BMW, which is an automotive manufacturer, residual value risk is a significant concern. The residual value of their vehicles can impact the company's financial performance and profitability. BMW may face residual value risk due to factors such as changing consumer preferences, advancements in technology, or economic conditions that could affect the future value of their cars.\n",
      "\n",
      "To mitigate residual value risk, automotive companies like BMW typically employ various strategies, including:\n",
      "\n",
      "1. Leasing and Finance Programs: Offering leasing and financing options to customers can help manage residual value risk. By retaining ownership of the vehicle during the lease term, BMW can control the residual value and generate revenue through monthly lease payments.\n",
      "\n",
      "2. Product Planning and Design: BMW may focus on designing vehicles with features and technologies that are likely to remain popular and desirable in the future, potentially increasing their residual values.\n",
      "\n",
      "3. Brand Reputation and Customer Loyalty: Building a strong brand image and fostering customer loyalty can positively influence residual values. BMW's reputation for quality and performance may encourage customers to choose their vehicles, even as they age.\n",
      "\n",
      "4. Certified Pre-Owned Programs: BMW has a certified pre-owned program that inspects and refurbishes used vehicles to meet certain standards. This program can help maintain the residual value of their cars by providing customers with a more reliable option when purchasing a used BMW.\n",
      "\n",
      "Unfortunately, I don't have specific information about AstraZeneca's residual value risk exposure or their risk mitigation strategies in this regard. It's important to note that residual value risk may not be as significant for companies in the pharmaceutical industry, like AstraZeneca, compared to industries with tangible depreciable assets.\n",
      "\n",
      "If you would like more detailed information about BMW's risk mitigation strategies, it would be best to refer to their annual reports, investor relations materials, or contact the company directly.\n"
     ]
    }
   ],
   "source": [
    "response = top_agent.chat(\"Do BMW or Astra Zeneca face residual value risks and how they mitigate these risks?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "- [Let's talb about LlamaIndex and LangChain](https://superwise.ai/blog/lets-talk-about-llamaindex-and-langchain/)\n",
    "- [LlamaIndex](https://docs.llamaindex.ai/en/stable/)\n",
    "- [Advanced RAG techniques - An illustrated overview](https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
