{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative AI and Risk Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Generative AI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Generative AI (GenAI) is a special type of Artificial Intelligence that can learn from and mimic large amounts of data to create content such as text, images, music, videos, code, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Generative AI in Risk Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Information analysis\n",
    "- Information provision\n",
    "- Information automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pwc.com/us/en/industries/financial-services/library/gen-ai-and-risk-management.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Proof-of-Concept (PoC): Risk bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the course we will develop a conversational AI that provides seamless information about risks and challenges faced by publicly listed companies based on their annual reports. More precisely we will develop an application where a Large Language Model (LLM) orchestrates user queries to the annual reports that are relevant for the query. The user's query will then be enriched with information from the relevant reports which allows the LLM to come up with answers that closely reflect the information from the reports. In other words, the generated answers from the LLM are tuned by a retrieval mechanism that adds domain knowledge to the LLM's response which it otherwise would not have from its pretraining. This mechanism is called Retrieval Augmented Generation (RAG) and is a quite popular approach when developing conversational GenAI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While risk-related information from company reports is publicly available, it is quite tedious and resource-intensive to collect and structure it and to make it seamless available to decision makers that base their decisions on such information. For example,\n",
    "- Financial Analysts and Investment Professionals such as portfolio managers, equity analysts, and hedge fund managers, need to assess the risks and challenges of companies to make informed investment decisions. A risk bot could help them quickly analyze risk disclosures in annual reports, saving time and improving accuracy.\n",
    "- Corporate Risk Managers need to benchmark their own risk disclosures against competitors or industry standards. A risk bot could help them identify trends in risk reporting and ensure compliance with regulatory requirements.\n",
    "- ESG analysts focus on evaluating companies' sustainability and governance practices. Risk disclosures in annual reports often include information about environmental and social risks, which are critical for ESG assessments. A risk bot could help them extracting and analyzing ESG-related risks from annual reports to evaluate a company's sustainability profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LLMs, are very large deep learning models that are pre-trained on vast amounts of data. They are highly flexible as a single model can perform completely different generative tasks such as answering questions, summarizing documents, translating languages and completing sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing LLM based applications requires you to choose one of the many proprietary or open-source LLM models. We use the proprietary LLM `command-r-plus` from [Cohere](https://cohere.com/command). Cohere offers trial keys that can be used to send calls to their LLMs free of charge. Cohere's trial keys are rate-limited, and cannot be used for commercial purposes.\n",
    "\n",
    "In order to get a trial key, [create an account](https://dashboard.cohere.com/welcome/register) on Cohere and create a new trial API key.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/cohere.png\" alt=\"Cohere trial key\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the root directory of this project simply create a new file named `.env` where you paste in the trial API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/env.png\" alt=\".env file\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step, we load the API keys into your project's environment, so the keys are available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API keys\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    SimpleDirectoryReader,\n",
    "    load_index_from_storage,\n",
    "    SummaryIndex,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    Document\n",
    ")\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.llms.cohere import Cohere\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.huggingface_api import HuggingFaceInferenceAPIEmbedding\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "from pathlib import Path\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [\n",
    "    'adidas',\n",
    "    'allianz',\n",
    "    'basf',\n",
    "    'bayer',\n",
    "    'beiersdorf',\n",
    "    'bmw'\n",
    "    ]\n",
    "\n",
    "year = '2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process = {\n",
    "    \"adidas\": {\n",
    "        \"pages\": range(166, 187, 1),\n",
    "        \"string_to_remove\": \"1 2 3 4 5 \\nT O  O U R SHA REHO L D ERS  GRO U P  MAN A GEMEN T  REP O RT – \\nO U R CO MPA N Y \\nGRO U P  MAN A GEMEN T  REP O RT – \\nF I N A N CI AL  REVI EW  \\nCO N SO L I DA T ED  FI N AN CI A L \\nST A T EMEN T S \\nA D D I T I ON A L I N FO RMA T I ON \\n \\n\\\\d{1,3} \\n    \\n    \\n A N N U A L  R E P O R T  2 0 2 3\",\n",
    "    },\n",
    "    \"allianz\": {\n",
    "        \"pages\": range(21, 35, 1),\n",
    "        \"string_to_remove\": \"B _ Management Report of Allianz SE \\n\\\\d{1,3} Annual Report 2023 – Allianz SE \\n\"\n",
    "    },\n",
    "    \"basf\": {\n",
    "        \"pages\": range(172, 184, 1),\n",
    "        \"string_to_remove\": \"Combined Management’s Report – Opportunities and Risks\\n\"\n",
    "    },\n",
    "    \"bayer\": {\n",
    "        \"pages\": range(100, 116, 1),\n",
    "        \"string_to_remove\": \" \\n \\nBayer Annual Report 2023 A Combined Management Report\\n3.2 Opportunity and Risk Report\\n \\\\d{1,3}\\n\"\n",
    "    },\n",
    "    \"beiersdorf\": {\n",
    "        \"pages\": range(155, 166, 1),\n",
    "        \"string_to_remove\": \" \\n \\nBeiersdorf Annual Report 2023 A Combined Management Report\\n3.2 Opportunity and Risk Report\\n \\\\d{1,3}\\n\"\n",
    "    },\n",
    "    \"bmw\": {\n",
    "        \"pages\": range(126, 142, 1),\n",
    "        \"string_to_remove\": r\"\\d{1,3} BMW Group Report 2023\\s+To Our Stakeholders\\s+Combined Management Report\\s+Group Financial Statements\\s+Responsibility Statement and Auditor’s Report\\s+Remuneration Report\\s+Other Information\\s+\\n\\s+Risks and Opportunities\\s+\\n\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_doc_tools(\n",
    "    company_fp: str,\n",
    "    company: int,\n",
    "    post_process: dict = None,\n",
    "    llm_model = Cohere(model=\"command-r-plus\", api_key=cohere_api_key),\n",
    "    embed_model = HuggingFaceInferenceAPIEmbedding(model_name=\"Snowflake/snowflake-arctic-embed-l-v2.0\", token=huggingface_api_key),\n",
    ") -> AgentRunner:\n",
    "    \n",
    "    # LLM model\n",
    "    Settings.llm = llm_model\n",
    "    # embedding model\n",
    "    Settings.embed_model = embed_model\n",
    "\n",
    "    if not os.path.exists(f\"./data/reports/{company}\"):\n",
    "        # load pdf documents\n",
    "        documents = SimpleDirectoryReader(input_files=[company_fp]).load_data()\n",
    "\n",
    "        if post_process is not None:\n",
    "            overall_text = \"\"\n",
    "            string_to_remove = post_process.get('string_to_remove')\n",
    "            for page in post_process.get('pages'):\n",
    "                document = documents[page]\n",
    "                text = document.text\n",
    "                if string_to_remove is not None:\n",
    "                    text = re.sub(string_to_remove, \"\", text)\n",
    "                overall_text = \"\\n\".join([overall_text, text])\n",
    "            documents = [Document(text=overall_text)]\n",
    "        \n",
    "        splitter = SentenceSplitter()\n",
    "        nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "        # summary index\n",
    "        summary_index = SummaryIndex(nodes)\n",
    "        summary_index.storage_context.persist(\n",
    "            persist_dir=f\"./data/reports/{company}/summary_index\"\n",
    "        )\n",
    "        # vector store index\n",
    "        vector_index = VectorStoreIndex(\n",
    "            nodes,\n",
    "            embed_model=Settings.embed_model)\n",
    "        vector_index.storage_context.persist(\n",
    "            persist_dir=f\"./data/reports/{company}/vector_index\"\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        summary_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(\n",
    "                persist_dir=f\"./data/reports/{company}/summary_index\"\n",
    "            )\n",
    "        )\n",
    "        vector_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(\n",
    "                persist_dir=f\"./data/reports/{company}/vector_index\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    # Summary query engine based on a\n",
    "    # simple retriever returns all nodes\n",
    "    summary_query_engine = summary_index.as_query_engine()\n",
    "\n",
    "    # Vector query engine based on a\n",
    "    # vector index retriever that only returns the top k results\n",
    "    vector_query_engine = vector_index.as_query_engine(similarity_top_k=2)\n",
    "\n",
    "    # define tools\n",
    "    query_engine_tools = [\n",
    "        QueryEngineTool.from_defaults(\n",
    "            name=f\"{company}_summary_tool\",\n",
    "            query_engine=summary_query_engine,\n",
    "            description=(\n",
    "                f\"Useful for summarization questions related to the risks outlined in the annual report of {company}.\"\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "        QueryEngineTool.from_defaults(\n",
    "            name=f\"{company}_vector_tool\",\n",
    "            query_engine=vector_query_engine,\n",
    "            description=(\n",
    "                f\"Useful for retrieving specific context concerning {company}'s risks and challenges as highlighted in its annual report.\"\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "        query_engine_tools, \n",
    "        llm=Settings.llm, \n",
    "        verbose=True,\n",
    "        system_prompt=f\"\"\"\n",
    "        You are an agent designed to answer queries about the company {company} which can be answered based on paragraphs \n",
    "        from their annual reports where they outline their risks and challenges.\n",
    "        \n",
    "\n",
    "\n",
    "        Please always use the tools provided to answer a question. Do NOT rely on prior knowledge.\n",
    "        \"\"\"\n",
    "    )\n",
    "    agent = AgentRunner(agent_worker)\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  5.95it/s]\n"
     ]
    }
   ],
   "source": [
    "agents = {}\n",
    "for company in tqdm(companies):\n",
    "    agent = await create_doc_tools(\n",
    "        company_fp = Path(f\"./data/raw/reports/{company}_{year}.pdf\"),\n",
    "        company = company,\n",
    "        post_process = post_process[company])\n",
    "    agents[company] = agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# define tool for each document agent\n",
    "all_tools = []\n",
    "for company in tqdm(companies):\n",
    "    report_summary = (\n",
    "        f\"This content contains information about {company}'s annual report. Use\"\n",
    "        f\" this tool if you want to answer any questions about {company}.\\n\"\n",
    "    )\n",
    "    doc_tool = QueryEngineTool(\n",
    "        query_engine=agents[company],\n",
    "        metadata=ToolMetadata(\n",
    "            name=f\"tool_{company}\",\n",
    "            description=report_summary,\n",
    "        ),\n",
    "    )\n",
    "    all_tools.append(doc_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot run the event loop while another loop is running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m obj_index \u001b[38;5;241m=\u001b[39m \u001b[43mObjectIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_tools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVectorStoreIndex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\objects\\base.py:172\u001b[0m, in \u001b[0;36mObjectIndex.from_objects\u001b[1;34m(cls, objects, object_mapping, from_node_fn, to_node_fn, index_cls, **index_kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     object_mapping \u001b[38;5;241m=\u001b[39m get_object_mapping(\n\u001b[0;32m    166\u001b[0m         objects,\n\u001b[0;32m    167\u001b[0m         from_node_fn\u001b[38;5;241m=\u001b[39mfrom_node_fn,\n\u001b[0;32m    168\u001b[0m         to_node_fn\u001b[38;5;241m=\u001b[39mto_node_fn,\n\u001b[0;32m    169\u001b[0m     )\n\u001b[0;32m    171\u001b[0m nodes \u001b[38;5;241m=\u001b[39m object_mapping\u001b[38;5;241m.\u001b[39mto_nodes(objects)\n\u001b[1;32m--> 172\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mindex_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mindex_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(index, object_mapping)\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:76\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     70\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embed_model\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m Settings\u001b[38;5;241m.\u001b[39membed_model\n\u001b[0;32m     73\u001b[0m )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:77\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m---> 77\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:310\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content_nodes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(nodes):\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome nodes are missing content, skipping them...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:279\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:232\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nodes_batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size):\n\u001b[1;32m--> 232\u001b[0m     nodes_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_with_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m     new_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39madd(nodes_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minsert_kwargs)\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mstores_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override:\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;66;03m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:139\u001b[0m, in \u001b[0;36mVectorStoreIndex._get_node_with_embedding\u001b[1;34m(self, nodes, show_progress)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_node_with_embedding\u001b[39m(\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    129\u001b[0m     nodes: Sequence[BaseNode],\n\u001b[0;32m    130\u001b[0m     show_progress: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    131\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseNode]:\n\u001b[0;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    Get tuples of id, node, and embedding.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m \n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m     id_to_embed_map \u001b[38;5;241m=\u001b[39m \u001b[43membed_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\indices\\utils.py:160\u001b[0m, in \u001b[0;36membed_nodes\u001b[1;34m(nodes, embed_model, show_progress)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m         id_to_embed_map[node\u001b[38;5;241m.\u001b[39mnode_id] \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39membedding\n\u001b[1;32m--> 160\u001b[0m new_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membed_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_embedding_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts_to_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_id, text_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[0;32m    165\u001b[0m     id_to_embed_map[new_id] \u001b[38;5;241m=\u001b[39m text_embedding\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py:335\u001b[0m, in \u001b[0;36mBaseEmbedding.get_text_embedding_batch\u001b[1;34m(self, texts, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    327\u001b[0m     EmbeddingStartEvent(\n\u001b[0;32m    328\u001b[0m         model_dict\u001b[38;5;241m=\u001b[39mmodel_dict,\n\u001b[0;32m    329\u001b[0m     )\n\u001b[0;32m    330\u001b[0m )\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    332\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mEMBEDDING,\n\u001b[0;32m    333\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mSERIALIZED: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dict()},\n\u001b[0;32m    334\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m--> 335\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_text_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     result_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[0;32m    337\u001b[0m     event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[0;32m    338\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    339\u001b[0m             EventPayload\u001b[38;5;241m.\u001b[39mCHUNKS: cur_batch,\n\u001b[0;32m    340\u001b[0m             EventPayload\u001b[38;5;241m.\u001b[39mEMBEDDINGS: embeddings,\n\u001b[0;32m    341\u001b[0m         },\n\u001b[0;32m    342\u001b[0m     )\n",
      "File \u001b[1;32mw:\\teaching\\risk_analytics\\.venv\\Lib\\site-packages\\llama_index\\embeddings\\huggingface\\base.py:517\u001b[0m, in \u001b[0;36mHuggingFaceInferenceAPIEmbedding._get_text_embeddings\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    514\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    515\u001b[0m         loop\u001b[38;5;241m.\u001b[39mcreate_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aget_text_embedding(text)) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts\n\u001b[0;32m    516\u001b[0m     ]\n\u001b[1;32m--> 517\u001b[0m     \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     loop\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\asyncio\\base_events.py:640\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m--> 640\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    642\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[0;32m    643\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\asyncio\\base_events.py:601\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot run the event loop while another loop is running"
     ]
    }
   ],
   "source": [
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_index.as_retriever(\n",
    "        similarity_top_k=3,\n",
    "        node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.8)]\n",
    "        ),\n",
    "    system_prompt=\"\"\"\n",
    "        You are an agent designed to answer queries about a set of given companies.\n",
    "        Please always try to use the tools provided to answer a question. \n",
    "        If none of the tools can be used to answer the question, respond to the user\n",
    "        that you do not have any information available about the company he is asking.\\n\n",
    "        \"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "top_agent = AgentRunner(top_agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What does the Norvatis mention about litigation risks in its annual report?\n",
      "=== LLM Response ===\n",
      "I'm sorry, I can only answer questions about BMW.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"I'm sorry, I can only answer questions about BMW.\", sources=[], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat(\"What does the Norvatis mention about litigation risks in its annual report?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Do BMW or Astra Zeneca face residual value risks and how they mitigate these risks?\n",
      "=== LLM Response ===\n",
      "I can provide some general information about residual value risk, but I don't have specific risk mitigation strategies for BMW or AstraZeneca. Here's what I can tell you:\n",
      "\n",
      "Residual value risk is the potential financial risk associated with the future value of an asset at the end of its lease or useful life. This risk is relevant for companies that deal with assets that depreciate over time, such as vehicles or equipment.\n",
      "\n",
      "For BMW, which is an automotive manufacturer, residual value risk is a significant concern. The residual value of their vehicles can impact the company's financial performance and profitability. BMW may face residual value risk due to factors such as changing consumer preferences, advancements in technology, or economic conditions that could affect the future value of their cars.\n",
      "\n",
      "To mitigate residual value risk, automotive companies like BMW typically employ various strategies, including:\n",
      "\n",
      "1. Leasing and Finance Programs: Offering leasing and financing options to customers can help manage residual value risk. By retaining ownership of the vehicle during the lease term, BMW can control the residual value and generate revenue through monthly lease payments.\n",
      "\n",
      "2. Product Planning and Design: BMW may focus on designing vehicles with features and technologies that are likely to remain popular and desirable in the future, potentially increasing their residual values.\n",
      "\n",
      "3. Brand Reputation and Customer Loyalty: Building a strong brand image and fostering customer loyalty can positively influence residual values. BMW's reputation for quality and performance may encourage customers to choose their vehicles, even as they age.\n",
      "\n",
      "4. Certified Pre-Owned Programs: BMW has a certified pre-owned program that inspects and refurbishes used vehicles to meet certain standards. This program can help maintain the residual value of their cars by providing customers with a more reliable option when purchasing a used BMW.\n",
      "\n",
      "Unfortunately, I don't have specific information about AstraZeneca's residual value risk exposure or their risk mitigation strategies in this regard. It's important to note that residual value risk may not be as significant for companies in the pharmaceutical industry, like AstraZeneca, compared to industries with tangible depreciable assets.\n",
      "\n",
      "If you would like more detailed information about BMW's risk mitigation strategies, it would be best to refer to their annual reports, investor relations materials, or contact the company directly.\n"
     ]
    }
   ],
   "source": [
    "response = top_agent.chat(\"Do BMW or Astra Zeneca face residual value risks and how they mitigate these risks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
